{
  "language": "elixir",
  "patterns": {
    "genserver": {
      "description": "Use GenServer for stateful processes with synchronous and asynchronous communication.",
      "whenToUse": "For managing state, handling requests, and building concurrent systems.",
      "example": "defmodule Counter do\n  use GenServer\n  \n  # Client API\n  \n  def start_link(initial_value \\\\ 0) do\n    GenServer.start_link(__MODULE__, initial_value, name: __MODULE__)\n  end\n  \n  def increment(pid \\\\ __MODULE__) do\n    GenServer.call(pid, :increment)\n  end\n  \n  def decrement(pid \\\\ __MODULE__) do\n    GenServer.call(pid, :decrement)\n  end\n  \n  def get_value(pid \\\\ __MODULE__) do\n    GenServer.call(pid, :get_value)\n  end\n  \n  def reset(pid \\\\ __MODULE__) do\n    GenServer.cast(pid, :reset)\n  end\n  \n  def increment_after(pid \\\\ __MODULE__, delay) do\n    GenServer.cast(pid, {:increment_after, delay})\n  end\n  \n  # Server Callbacks\n  \n  @impl true\n  def init(initial_value) do\n    {:ok, %{value: initial_value}}\n  end\n  \n  @impl true\n  def handle_call(:increment, _from, state) do\n    new_value = state.value + 1\n    {:reply, new_value, %{state | value: new_value}}\n  end\n  \n  @impl true\n  def handle_call(:decrement, _from, state) do\n    new_value = state.value - 1\n    {:reply, new_value, %{state | value: new_value}}\n  end\n  \n  @impl true\n  def handle_call(:get_value, _from, state) do\n    {:reply, state.value, state}\n  end\n  \n  @impl true\n  def handle_cast(:reset, _state) do\n    {:noreply, %{value: 0}}\n  end\n  \n  @impl true\n  def handle_cast({:increment_after, delay}, state) do\n    Process.send_after(self(), :delayed_increment, delay)\n    {:noreply, state}\n  end\n  \n  @impl true\n  def handle_info(:delayed_increment, state) do\n    {:noreply, %{state | value: state.value + 1}}\n  end\n  \n  @impl true\n  def handle_info(_msg, state) do\n    {:noreply, state}\n  end\nend\n\n# Advanced GenServer with state management\ndefmodule SessionManager do\n  use GenServer\n  require Logger\n  \n  defmodule State do\n    defstruct sessions: %{}, \n              max_sessions: 1000,\n              timeout: :timer.minutes(30)\n  end\n  \n  # Client API\n  \n  def start_link(opts \\\\ []) do\n    GenServer.start_link(__MODULE__, opts, name: __MODULE__)\n  end\n  \n  def create_session(user_id, metadata \\\\ %{}) do\n    GenServer.call(__MODULE__, {:create_session, user_id, metadata})\n  end\n  \n  def get_session(session_id) do\n    GenServer.call(__MODULE__, {:get_session, session_id})\n  end\n  \n  def update_session(session_id, updates) do\n    GenServer.call(__MODULE__, {:update_session, session_id, updates})\n  end\n  \n  def delete_session(session_id) do\n    GenServer.cast(__MODULE__, {:delete_session, session_id})\n  end\n  \n  def active_sessions do\n    GenServer.call(__MODULE__, :active_sessions)\n  end\n  \n  # Server Callbacks\n  \n  @impl true\n  def init(opts) do\n    state = %State{\n      max_sessions: Keyword.get(opts, :max_sessions, 1000),\n      timeout: Keyword.get(opts, :timeout, :timer.minutes(30))\n    }\n    \n    # Schedule periodic cleanup\n    schedule_cleanup()\n    \n    {:ok, state}\n  end\n  \n  @impl true\n  def handle_call({:create_session, user_id, metadata}, _from, state) do\n    if map_size(state.sessions) >= state.max_sessions do\n      {:reply, {:error, :max_sessions_reached}, state}\n    else\n      session_id = generate_session_id()\n      session = %{\n        id: session_id,\n        user_id: user_id,\n        metadata: metadata,\n        created_at: DateTime.utc_now(),\n        last_accessed: DateTime.utc_now(),\n        expires_at: DateTime.add(DateTime.utc_now(), state.timeout, :millisecond)\n      }\n      \n      new_sessions = Map.put(state.sessions, session_id, session)\n      {:reply, {:ok, session_id}, %{state | sessions: new_sessions}}\n    end\n  end\n  \n  @impl true\n  def handle_call({:get_session, session_id}, _from, state) do\n    case Map.get(state.sessions, session_id) do\n      nil -> \n        {:reply, {:error, :not_found}, state}\n      session ->\n        # Update last accessed time\n        updated_session = %{session | \n          last_accessed: DateTime.utc_now(),\n          expires_at: DateTime.add(DateTime.utc_now(), state.timeout, :millisecond)\n        }\n        new_sessions = Map.put(state.sessions, session_id, updated_session)\n        {:reply, {:ok, updated_session}, %{state | sessions: new_sessions}}\n    end\n  end\n  \n  @impl true\n  def handle_call({:update_session, session_id, updates}, _from, state) do\n    case Map.get(state.sessions, session_id) do\n      nil -> \n        {:reply, {:error, :not_found}, state}\n      session ->\n        updated_session = Map.merge(session, updates)\n        new_sessions = Map.put(state.sessions, session_id, updated_session)\n        {:reply, {:ok, updated_session}, %{state | sessions: new_sessions}}\n    end\n  end\n  \n  @impl true\n  def handle_call(:active_sessions, _from, state) do\n    count = map_size(state.sessions)\n    {:reply, count, state}\n  end\n  \n  @impl true\n  def handle_cast({:delete_session, session_id}, state) do\n    new_sessions = Map.delete(state.sessions, session_id)\n    {:noreply, %{state | sessions: new_sessions}}\n  end\n  \n  @impl true\n  def handle_info(:cleanup_expired, state) do\n    now = DateTime.utc_now()\n    \n    new_sessions = state.sessions\n    |> Enum.filter(fn {_id, session} -> \n      DateTime.compare(session.expires_at, now) == :gt\n    end)\n    |> Enum.into(%{})\n    \n    expired_count = map_size(state.sessions) - map_size(new_sessions)\n    if expired_count > 0 do\n      Logger.info(\"Cleaned up #{expired_count} expired sessions\")\n    end\n    \n    schedule_cleanup()\n    {:noreply, %{state | sessions: new_sessions}}\n  end\n  \n  # Private functions\n  \n  defp generate_session_id do\n    :crypto.strong_rand_bytes(16) |> Base.url_encode64(padding: false)\n  end\n  \n  defp schedule_cleanup do\n    Process.send_after(self(), :cleanup_expired, :timer.minutes(5))\n  end\nend"
    },
    "supervisor": {
      "description": "Design supervision trees for fault-tolerant systems with automatic recovery.",
      "whenToUse": "For building resilient applications that can recover from failures.",
      "example": "defmodule MyApp.Supervisor do\n  use Supervisor\n  \n  def start_link(opts) do\n    Supervisor.start_link(__MODULE__, opts, name: __MODULE__)\n  end\n  \n  @impl true\n  def init(_opts) do\n    children = [\n      # Permanent worker - always restarted\n      {MyApp.DatabaseConnection, []},\n      \n      # Temporary worker - never restarted\n      %{\n        id: MyApp.TempWorker,\n        start: {MyApp.TempWorker, :start_link, []},\n        restart: :temporary\n      },\n      \n      # Transient worker - restarted only on abnormal termination\n      %{\n        id: MyApp.JobProcessor,\n        start: {MyApp.JobProcessor, :start_link, []},\n        restart: :transient\n      },\n      \n      # Worker with custom restart intensity\n      %{\n        id: MyApp.ApiClient,\n        start: {MyApp.ApiClient, :start_link, []},\n        restart: :permanent,\n        shutdown: 5000,\n        type: :worker\n      },\n      \n      # Child supervisor\n      {MyApp.WorkerSupervisor, []},\n      \n      # Dynamic supervisor for on-demand children\n      {DynamicSupervisor, strategy: :one_for_one, name: MyApp.DynamicSupervisor}\n    ]\n    \n    # Supervision strategies:\n    # - :one_for_one - only restart the failed child\n    # - :one_for_all - restart all children if one fails\n    # - :rest_for_one - restart failed child and all children started after it\n    # - :simple_one_for_one - for dynamically spawned children (deprecated, use DynamicSupervisor)\n    \n    opts = [\n      strategy: :one_for_all,\n      max_restarts: 3,\n      max_seconds: 5\n    ]\n    \n    Supervisor.init(children, opts)\n  end\nend\n\n# Specialized supervisor with different strategies\ndefmodule MyApp.WorkerSupervisor do\n  use Supervisor\n  \n  def start_link(opts) do\n    Supervisor.start_link(__MODULE__, opts, name: __MODULE__)\n  end\n  \n  @impl true\n  def init(_opts) do\n    children = [\n      # Group 1: Database workers (one_for_all)\n      %{\n        id: :db_supervisor,\n        start: {Supervisor, :start_link, [\n          [\n            {MyApp.DbConnectionPool, []},\n            {MyApp.DbQueryCache, []},\n            {MyApp.DbReplicator, []}\n          ],\n          [strategy: :one_for_all, name: MyApp.DbSupervisor]\n        ]},\n        type: :supervisor\n      },\n      \n      # Group 2: Processing workers (rest_for_one)\n      %{\n        id: :processing_supervisor,\n        start: {Supervisor, :start_link, [\n          [\n            {MyApp.EventProducer, []},\n            {MyApp.EventProcessor, []},\n            {MyApp.EventConsumer, []}\n          ],\n          [strategy: :rest_for_one, name: MyApp.ProcessingSupervisor]\n        ]},\n        type: :supervisor\n      }\n    ]\n    \n    Supervisor.init(children, strategy: :one_for_one)\n  end\nend\n\n# Dynamic worker spawning\ndefmodule MyApp.WorkerManager do\n  use GenServer\n  \n  def start_link(opts) do\n    GenServer.start_link(__MODULE__, opts, name: __MODULE__)\n  end\n  \n  def start_worker(worker_args) do\n    GenServer.call(__MODULE__, {:start_worker, worker_args})\n  end\n  \n  def stop_worker(worker_id) do\n    GenServer.call(__MODULE__, {:stop_worker, worker_id})\n  end\n  \n  def list_workers do\n    GenServer.call(__MODULE__, :list_workers)\n  end\n  \n  @impl true\n  def init(_opts) do\n    {:ok, %{workers: %{}}}\n  end\n  \n  @impl true\n  def handle_call({:start_worker, args}, _from, state) do\n    worker_spec = %{\n      id: generate_worker_id(),\n      start: {MyApp.Worker, :start_link, [args]},\n      restart: :transient\n    }\n    \n    case DynamicSupervisor.start_child(MyApp.DynamicSupervisor, worker_spec) do\n      {:ok, pid} ->\n        worker_id = worker_spec.id\n        new_workers = Map.put(state.workers, worker_id, {pid, args})\n        {:reply, {:ok, worker_id, pid}, %{state | workers: new_workers}}\n      \n      {:error, reason} ->\n        {:reply, {:error, reason}, state}\n    end\n  end\n  \n  @impl true\n  def handle_call({:stop_worker, worker_id}, _from, state) do\n    case Map.get(state.workers, worker_id) do\n      {pid, _args} ->\n        case DynamicSupervisor.terminate_child(MyApp.DynamicSupervisor, pid) do\n          :ok ->\n            new_workers = Map.delete(state.workers, worker_id)\n            {:reply, :ok, %{state | workers: new_workers}}\n          \n          {:error, reason} ->\n            {:reply, {:error, reason}, state}\n        end\n      \n      nil ->\n        {:reply, {:error, :not_found}, state}\n    end\n  end\n  \n  @impl true\n  def handle_call(:list_workers, _from, state) do\n    workers = Enum.map(state.workers, fn {id, {pid, args}} ->\n      %{id: id, pid: pid, args: args, alive: Process.alive?(pid)}\n    end)\n    {:reply, workers, state}\n  end\n  \n  defp generate_worker_id do\n    \"worker_#{:erlang.unique_integer([:positive, :monotonic])}\"\n  end\nend\n\n# Supervisor with custom child specs\ndefmodule MyApp.CustomSupervisor do\n  use Supervisor\n  \n  def start_link(opts) do\n    Supervisor.start_link(__MODULE__, opts, name: __MODULE__)\n  end\n  \n  @impl true\n  def init(opts) do\n    children = [\n      # Using Supervisor.child_spec/2 for customization\n      Supervisor.child_spec(\n        {MyApp.Worker, arg: \"value\"},\n        id: :worker_1,\n        restart: :permanent,\n        shutdown: 10_000\n      ),\n      \n      # Task supervisor for async tasks\n      {Task.Supervisor, name: MyApp.TaskSupervisor},\n      \n      # Registry for process discovery\n      {Registry, keys: :unique, name: MyApp.Registry},\n      \n      # Partition supervisor for load distribution\n      {PartitionSupervisor,\n        child_spec: MyApp.PartitionWorker,\n        name: MyApp.PartitionSupervisor,\n        partitions: System.schedulers_online()\n      }\n    ]\n    \n    Supervisor.init(children, strategy: :one_for_one)\n  end\nend"
    },
    "pipeline": {
      "description": "Use the pipe operator for data transformation pipelines.",
      "whenToUse": "For sequential data transformations and functional composition.",
      "example": "defmodule DataPipeline do\n  # Basic pipeline\n  def process_user_data(raw_data) do\n    raw_data\n    |> parse_json()\n    |> validate_fields()\n    |> normalize_data()\n    |> enrich_with_metadata()\n    |> save_to_database()\n  end\n  \n  # Pipeline with error handling\n  def safe_process(data) do\n    data\n    |> validate()\n    |> case do\n      {:ok, valid_data} ->\n        valid_data\n        |> transform()\n        |> persist()\n      \n      {:error, _} = error ->\n        error\n    end\n  end\n  \n  # Pipeline with Stream for large datasets\n  def process_large_file(file_path) do\n    file_path\n    |> File.stream!()\n    |> Stream.map(&String.trim/1)\n    |> Stream.filter(&(String.length(&1) > 0))\n    |> Stream.map(&parse_line/1)\n    |> Stream.filter(&valid?/1)\n    |> Stream.map(&transform/1)\n    |> Stream.chunk_every(1000)\n    |> Stream.each(&batch_insert/1)\n    |> Stream.run()\n  end\n  \n  # Complex pipeline with multiple branches\n  def analyze_logs(log_file) do\n    base_stream = log_file\n    |> File.stream!()\n    |> Stream.map(&LogParser.parse/1)\n    |> Stream.filter(&match?({:ok, _}, &1))\n    |> Stream.map(fn {:ok, log} -> log end)\n    \n    # Branch 1: Error analysis\n    error_task = Task.async(fn ->\n      base_stream\n      |> Stream.filter(&(&1.level == :error))\n      |> Enum.frequencies_by(& &1.error_type)\n    end)\n    \n    # Branch 2: Performance metrics\n    perf_task = Task.async(fn ->\n      base_stream\n      |> Stream.filter(&(&1.type == :request))\n      |> Stream.map(& &1.duration)\n      |> Enum.to_list()\n      |> calculate_percentiles()\n    end)\n    \n    # Branch 3: User activity\n    activity_task = Task.async(fn ->\n      base_stream\n      |> Stream.filter(&(&1.user_id != nil))\n      |> Stream.map(& &1.user_id)\n      |> Enum.frequencies()\n      |> Enum.sort_by(fn {_user, count} -> count end, :desc)\n      |> Enum.take(10)\n    end)\n    \n    # Gather results\n    %{\n      errors: Task.await(error_task),\n      performance: Task.await(perf_task),\n      top_users: Task.await(activity_task)\n    }\n  end\n  \n  # Pipeline with custom operators\n  defmodule PipelineOperators do\n    # Conditional pipe\n    defmacro pipe_if(value, condition, fun) do\n      quote do\n        if unquote(condition) do\n          unquote(value) |> unquote(fun)\n        else\n          unquote(value)\n        end\n      end\n    end\n    \n    # Tap pipe (execute side effect but return original value)\n    def tap(value, fun) do\n      fun.(value)\n      value\n    end\n    \n    # Maybe pipe (only continue if not nil)\n    def maybe_pipe(nil, _fun), do: nil\n    def maybe_pipe(value, fun), do: fun.(value)\n  end\n  \n  # Using with for complex pipelines\n  def complex_operation(params) do\n    with {:ok, validated} <- validate_params(params),\n         {:ok, user} <- fetch_user(validated.user_id),\n         {:ok, processed} <- process_data(validated.data, user),\n         {:ok, result} <- save_results(processed) do\n      {:ok, enrich_response(result, user)}\n    else\n      {:error, :validation_failed} = error ->\n        Logger.error(\"Validation failed: #{inspect(params)}\")\n        error\n      \n      {:error, :user_not_found} = error ->\n        Logger.error(\"User not found: #{validated.user_id}\")\n        error\n      \n      {:error, reason} = error ->\n        Logger.error(\"Operation failed: #{inspect(reason)}\")\n        error\n    end\n  end\n  \n  # Telemetry pipeline\n  def instrumented_pipeline(data) do\n    start_time = System.monotonic_time()\n    \n    result = data\n    |> tap(&emit_telemetry_event(:pipeline_started, &1))\n    |> validate()\n    |> tap(&emit_telemetry_event(:validation_complete, &1))\n    |> transform()\n    |> tap(&emit_telemetry_event(:transformation_complete, &1))\n    |> persist()\n    |> tap(&emit_telemetry_event(:persistence_complete, &1))\n    \n    duration = System.monotonic_time() - start_time\n    \n    :telemetry.execute(\n      [:pipeline, :complete],\n      %{duration: duration},\n      %{result: result}\n    )\n    \n    result\n  end\n  \n  defp emit_telemetry_event(event, data) do\n    :telemetry.execute(\n      [:pipeline, event],\n      %{timestamp: System.system_time()},\n      %{data: data}\n    )\n  end\nend\n\n# Flow-based pipeline for parallel processing\ndefmodule ParallelPipeline do\n  use Flow\n  \n  def process_csv(file_path) do\n    file_path\n    |> File.stream!()\n    |> Flow.from_enumerable()\n    |> Flow.partition()\n    |> Flow.map(&parse_csv_line/1)\n    |> Flow.filter(&valid_record?/1)\n    |> Flow.map(&transform_record/1)\n    |> Flow.group_by(&(&1.category))\n    |> Flow.map(fn {category, records} ->\n      {category, calculate_statistics(records)}\n    end)\n    |> Enum.to_list()\n  end\nend"
    },
    "actor_model": {
      "description": "Implement the actor model with message passing and process isolation.",
      "whenToUse": "For building concurrent, distributed, and fault-tolerant systems.",
      "example": "defmodule ActorExample do\n  # Simple actor using spawn and message passing\n  def simple_actor do\n    spawn(fn -> actor_loop(%{count: 0}) end)\n  end\n  \n  defp actor_loop(state) do\n    receive do\n      {:increment, from} ->\n        new_state = %{state | count: state.count + 1}\n        send(from, {:count, new_state.count})\n        actor_loop(new_state)\n      \n      {:get_count, from} ->\n        send(from, {:count, state.count})\n        actor_loop(state)\n      \n      :stop ->\n        :ok  # Terminate the actor\n      \n      unknown ->\n        IO.puts(\"Unknown message: #{inspect(unknown)}\")\n        actor_loop(state)\n    end\n  end\n  \n  # Usage\n  def demo do\n    actor = simple_actor()\n    \n    send(actor, {:increment, self()})\n    receive do\n      {:count, count} -> IO.puts(\"Count: #{count}\")\n    end\n    \n    send(actor, :stop)\n  end\nend\n\n# Agent-based actor for simpler state management\ndefmodule BankAccount do\n  use Agent\n  \n  defstruct balance: 0, transactions: []\n  \n  def start_link(initial_balance \\\\ 0) do\n    Agent.start_link(fn -> \n      %__MODULE__{balance: initial_balance}\n    end, name: __MODULE__)\n  end\n  \n  def deposit(amount) when amount > 0 do\n    Agent.update(__MODULE__, fn account ->\n      transaction = %{type: :deposit, amount: amount, timestamp: DateTime.utc_now()}\n      \n      %{account | \n        balance: account.balance + amount,\n        transactions: [transaction | account.transactions]\n      }\n    end)\n  end\n  \n  def withdraw(amount) when amount > 0 do\n    Agent.get_and_update(__MODULE__, fn account ->\n      if account.balance >= amount do\n        transaction = %{type: :withdrawal, amount: amount, timestamp: DateTime.utc_now()}\n        \n        new_account = %{account | \n          balance: account.balance - amount,\n          transactions: [transaction | account.transactions]\n        }\n        \n        {{:ok, amount}, new_account}\n      else\n        {{:error, :insufficient_funds}, account}\n      end\n    end)\n  end\n  \n  def get_balance do\n    Agent.get(__MODULE__, & &1.balance)\n  end\n  \n  def get_transactions(limit \\\\ 10) do\n    Agent.get(__MODULE__, fn account ->\n      Enum.take(account.transactions, limit)\n    end)\n  end\nend\n\n# Task-based actors for concurrent operations\ndefmodule TaskActor do\n  def parallel_map(collection, fun) do\n    collection\n    |> Enum.map(&Task.async(fn -> fun.(&1) end))\n    |> Enum.map(&Task.await/1)\n  end\n  \n  def parallel_each(collection, fun, timeout \\\\ 5000) do\n    collection\n    |> Enum.map(&Task.async(fn -> fun.(&1) end))\n    |> Task.yield_many(timeout)\n    |> Enum.map(fn {task, res} ->\n      case res do\n        {:ok, value} -> value\n        nil -> \n          Task.shutdown(task, :brutal_kill)\n          {:error, :timeout}\n      end\n    end)\n  end\n  \n  # Supervised tasks\n  def safe_async(fun) do\n    Task.Supervisor.async_nolink(MyApp.TaskSupervisor, fun)\n  end\n  \n  def distributed_work(nodes, work_items) do\n    work_items\n    |> Enum.with_index()\n    |> Enum.map(fn {item, index} ->\n      node = Enum.at(nodes, rem(index, length(nodes)))\n      \n      Task.Supervisor.async(\n        {MyApp.TaskSupervisor, node},\n        fn -> process_item(item) end\n      )\n    end)\n    |> Enum.map(&Task.await(&1, 30_000))\n  end\nend\n\n# Registry-based actors\ndefmodule GameServer do\n  use GenServer\n  \n  def start_link(game_id) do\n    GenServer.start_link(__MODULE__, game_id, \n      name: {:via, Registry, {MyApp.GameRegistry, game_id}})\n  end\n  \n  def join_game(game_id, player_id) do\n    GenServer.call({:via, Registry, {MyApp.GameRegistry, game_id}}, \n      {:join, player_id})\n  end\n  \n  def make_move(game_id, player_id, move) do\n    GenServer.call({:via, Registry, {MyApp.GameRegistry, game_id}}, \n      {:move, player_id, move})\n  end\n  \n  def get_state(game_id) do\n    GenServer.call({:via, Registry, {MyApp.GameRegistry, game_id}}, :get_state)\n  end\n  \n  # Find all active games\n  def list_games do\n    Registry.select(MyApp.GameRegistry, [{{:\"$1\", :_, :_}, [], [:\"$1\"]}])\n  end\n  \n  @impl true\n  def init(game_id) do\n    state = %{\n      id: game_id,\n      players: [],\n      moves: [],\n      status: :waiting_for_players,\n      created_at: DateTime.utc_now()\n    }\n    \n    {:ok, state}\n  end\n  \n  @impl true\n  def handle_call({:join, player_id}, _from, state) do\n    if length(state.players) < 2 do\n      new_players = [player_id | state.players]\n      new_state = %{state | \n        players: new_players,\n        status: if(length(new_players) == 2, do: :in_progress, else: :waiting_for_players)\n      }\n      \n      {:reply, :ok, new_state}\n    else\n      {:reply, {:error, :game_full}, state}\n    end\n  end\n  \n  @impl true\n  def handle_call({:move, player_id, move}, _from, state) do\n    if player_id in state.players and state.status == :in_progress do\n      new_move = %{player: player_id, move: move, timestamp: DateTime.utc_now()}\n      new_state = %{state | moves: [new_move | state.moves]}\n      \n      # Check for game end condition\n      new_state = if game_over?(new_state) do\n        %{new_state | status: :finished}\n      else\n        new_state\n      end\n      \n      {:reply, {:ok, new_state.status}, new_state}\n    else\n      {:reply, {:error, :invalid_move}, state}\n    end\n  end\n  \n  @impl true\n  def handle_call(:get_state, _from, state) do\n    {:reply, state, state}\n  end\n  \n  defp game_over?(_state) do\n    # Game-specific logic\n    false\n  end\nend"
    },
    "phoenix_contexts": {
      "description": "Organize code using Phoenix contexts for domain-driven design.",
      "whenToUse": "For structuring large applications with clear boundaries.",
      "example": "# Context module - the public API\ndefmodule MyApp.Accounts do\n  @moduledoc \"\"\"\n  The Accounts context handles user authentication and management.\n  \"\"\"\n  \n  import Ecto.Query, warn: false\n  alias MyApp.Repo\n  alias MyApp.Accounts.{User, Credential, Session}\n  \n  # User management\n  \n  def list_users(opts \\\\ []) do\n    User\n    |> apply_filters(opts)\n    |> Repo.all()\n  end\n  \n  def get_user!(id), do: Repo.get!(User, id)\n  \n  def get_user(id), do: Repo.get(User, id)\n  \n  def get_user_by(clauses), do: Repo.get_by(User, clauses)\n  \n  def create_user(attrs \\\\ %{}) do\n    %User{}\n    |> User.changeset(attrs)\n    |> Ecto.Changeset.cast_assoc(:credential, with: &Credential.changeset/2)\n    |> Repo.insert()\n  end\n  \n  def update_user(%User{} = user, attrs) do\n    user\n    |> User.changeset(attrs)\n    |> Repo.update()\n  end\n  \n  def delete_user(%User{} = user) do\n    Repo.delete(user)\n  end\n  \n  def change_user(%User{} = user, attrs \\\\ %{}) do\n    User.changeset(user, attrs)\n  end\n  \n  # Authentication\n  \n  def authenticate_user(email, password) do\n    user = get_user_by(email: email)\n    \n    with %User{} <- user,\n         %Credential{} = credential <- user.credential,\n         true <- Credential.valid_password?(credential, password) do\n      {:ok, user}\n    else\n      _ -> {:error, :invalid_credentials}\n    end\n  end\n  \n  def create_session(%User{} = user, attrs \\\\ %{}) do\n    %Session{}\n    |> Session.changeset(attrs)\n    |> Ecto.Changeset.put_assoc(:user, user)\n    |> Repo.insert()\n  end\n  \n  def get_session(token) do\n    Session\n    |> where(token: ^token)\n    |> where([s], s.expires_at > ^DateTime.utc_now())\n    |> preload(:user)\n    |> Repo.one()\n  end\n  \n  def delete_session(%Session{} = session) do\n    Repo.delete(session)\n  end\n  \n  # Complex business logic\n  \n  def register_user(attrs) do\n    Ecto.Multi.new()\n    |> Ecto.Multi.insert(:user, User.registration_changeset(%User{}, attrs))\n    |> Ecto.Multi.run(:send_email, fn _repo, %{user: user} ->\n      MyApp.Mailer.deliver_welcome_email(user)\n      {:ok, :email_sent}\n    end)\n    |> Ecto.Multi.run(:track_event, fn _repo, %{user: user} ->\n      MyApp.Analytics.track(\"user_registered\", %{user_id: user.id})\n      {:ok, :tracked}\n    end)\n    |> Repo.transaction()\n    |> case do\n      {:ok, %{user: user}} -> {:ok, user}\n      {:error, :user, changeset, _} -> {:error, changeset}\n      {:error, _, _, _} -> {:error, :registration_failed}\n    end\n  end\n  \n  # Private functions\n  \n  defp apply_filters(query, opts) do\n    Enum.reduce(opts, query, fn\n      {:role, role}, query ->\n        where(query, [u], u.role == ^role)\n      \n      {:active, true}, query ->\n        where(query, [u], not is_nil(u.confirmed_at))\n      \n      {:search, term}, query ->\n        where(query, [u], ilike(u.email, ^\"%#{term}%\") or ilike(u.name, ^\"%#{term}%\"))\n      \n      {:order_by, field}, query ->\n        order_by(query, [u], ^field)\n      \n      {:limit, limit}, query ->\n        limit(query, ^limit)\n      \n      _, query ->\n        query\n    end)\n  end\nend\n\n# Schema modules - internal to the context\ndefmodule MyApp.Accounts.User do\n  use Ecto.Schema\n  import Ecto.Changeset\n  \n  schema \"users\" do\n    field :email, :string\n    field :name, :string\n    field :role, :string, default: \"user\"\n    field :confirmed_at, :utc_datetime\n    \n    has_one :credential, MyApp.Accounts.Credential\n    has_many :sessions, MyApp.Accounts.Session\n    \n    timestamps()\n  end\n  \n  def changeset(user, attrs) do\n    user\n    |> cast(attrs, [:email, :name, :role])\n    |> validate_required([:email, :name])\n    |> validate_format(:email, ~r/@/)\n    |> unique_constraint(:email)\n  end\n  \n  def registration_changeset(user, attrs) do\n    user\n    |> changeset(attrs)\n    |> cast_assoc(:credential, required: true, with: &MyApp.Accounts.Credential.changeset/2)\n  end\nend\n\ndefmodule MyApp.Accounts.Credential do\n  use Ecto.Schema\n  import Ecto.Changeset\n  \n  schema \"credentials\" do\n    field :password, :string, virtual: true\n    field :password_hash, :string\n    \n    belongs_to :user, MyApp.Accounts.User\n    \n    timestamps()\n  end\n  \n  def changeset(credential, attrs) do\n    credential\n    |> cast(attrs, [:password])\n    |> validate_required([:password])\n    |> validate_length(:password, min: 8)\n    |> put_password_hash()\n  end\n  \n  defp put_password_hash(%{valid?: true, changes: %{password: password}} = changeset) do\n    put_change(changeset, :password_hash, Bcrypt.hash_pwd_salt(password))\n  end\n  defp put_password_hash(changeset), do: changeset\n  \n  def valid_password?(%__MODULE__{password_hash: hash}, password) do\n    Bcrypt.verify_pass(password, hash)\n  end\nend\n\n# Cross-context communication\ndefmodule MyApp.Sales do\n  alias MyApp.Accounts\n  \n  def create_order(user_id, items) do\n    with {:ok, user} <- Accounts.get_user(user_id),\n         {:ok, order} <- do_create_order(user, items) do\n      # Notify other contexts\n      MyApp.Inventory.reserve_items(order.items)\n      MyApp.Notifications.send_order_confirmation(user, order)\n      \n      {:ok, order}\n    end\n  end\nend"
    },
    "distributed_systems": {
      "description": "Build distributed systems using nodes, clustering, and process groups.",
      "whenToUse": "For scalable applications that need to run across multiple machines.",
      "example": "defmodule DistributedSystem do\n  # Node connection and monitoring\n  defmodule NodeManager do\n    use GenServer\n    require Logger\n    \n    def start_link(opts) do\n      GenServer.start_link(__MODULE__, opts, name: __MODULE__)\n    end\n    \n    def connect_node(node_name) do\n      GenServer.call(__MODULE__, {:connect, node_name})\n    end\n    \n    def list_nodes do\n      GenServer.call(__MODULE__, :list_nodes)\n    end\n    \n    @impl true\n    def init(_opts) do\n      # Monitor node connections\n      :net_kernel.monitor_nodes(true)\n      \n      state = %{\n        connected_nodes: MapSet.new(),\n        node_info: %{}\n      }\n      \n      {:ok, state}\n    end\n    \n    @impl true\n    def handle_call({:connect, node_name}, _from, state) do\n      case Node.connect(node_name) do\n        true ->\n          Logger.info(\"Connected to node: #{node_name}\")\n          new_state = %{state | \n            connected_nodes: MapSet.put(state.connected_nodes, node_name)\n          }\n          {:reply, :ok, new_state}\n        \n        false ->\n          Logger.error(\"Failed to connect to node: #{node_name}\")\n          {:reply, {:error, :connection_failed}, state}\n      end\n    end\n    \n    @impl true\n    def handle_call(:list_nodes, _from, state) do\n      nodes = Node.list() ++ [node()]\n      {:reply, nodes, state}\n    end\n    \n    @impl true\n    def handle_info({:nodeup, node}, state) do\n      Logger.info(\"Node connected: #{node}\")\n      \n      # Sync data with new node\n      send({__MODULE__, node}, {:sync_request, node(), state.node_info})\n      \n      new_state = %{state | \n        connected_nodes: MapSet.put(state.connected_nodes, node)\n      }\n      {:noreply, new_state}\n    end\n    \n    @impl true\n    def handle_info({:nodedown, node}, state) do\n      Logger.warn(\"Node disconnected: #{node}\")\n      \n      new_state = %{state | \n        connected_nodes: MapSet.delete(state.connected_nodes, node),\n        node_info: Map.delete(state.node_info, node)\n      }\n      {:noreply, new_state}\n    end\n  end\n  \n  # Distributed cache using :pg (process groups)\n  defmodule DistributedCache do\n    use GenServer\n    \n    @cache_group :distributed_cache\n    \n    def start_link(opts) do\n      GenServer.start_link(__MODULE__, opts, name: __MODULE__)\n    end\n    \n    def put(key, value, ttl \\\\ :infinity) do\n      # Broadcast to all cache instances\n      for pid <- :pg.get_members(@cache_group) do\n        GenServer.cast(pid, {:put, key, value, ttl})\n      end\n    end\n    \n    def get(key) do\n      # Try local first\n      case GenServer.call(__MODULE__, {:get, key}) do\n        {:ok, value} -> {:ok, value}\n        :not_found -> \n          # Try other nodes\n          get_from_cluster(key)\n      end\n    end\n    \n    def delete(key) do\n      for pid <- :pg.get_members(@cache_group) do\n        GenServer.cast(pid, {:delete, key})\n      end\n    end\n    \n    @impl true\n    def init(_opts) do\n      # Join the process group\n      :pg.join(@cache_group, self())\n      \n      # ETS table for local storage\n      table = :ets.new(:cache_table, [:set, :private])\n      \n      state = %{\n        table: table,\n        ttl_timers: %{}\n      }\n      \n      {:ok, state}\n    end\n    \n    @impl true\n    def handle_call({:get, key}, _from, state) do\n      case :ets.lookup(state.table, key) do\n        [{^key, value, _expiry}] -> {:reply, {:ok, value}, state}\n        [] -> {:reply, :not_found, state}\n      end\n    end\n    \n    @impl true\n    def handle_cast({:put, key, value, ttl}, state) do\n      expiry = if ttl == :infinity do\n        :infinity\n      else\n        System.system_time(:millisecond) + ttl\n      end\n      \n      # Cancel existing timer if any\n      state = cancel_ttl_timer(state, key)\n      \n      # Store in ETS\n      :ets.insert(state.table, {key, value, expiry})\n      \n      # Set up TTL timer if needed\n      state = if ttl != :infinity do\n        timer_ref = Process.send_after(self(), {:expire, key}, ttl)\n        put_in(state.ttl_timers[key], timer_ref)\n      else\n        state\n      end\n      \n      {:noreply, state}\n    end\n    \n    @impl true\n    def handle_cast({:delete, key}, state) do\n      :ets.delete(state.table, key)\n      state = cancel_ttl_timer(state, key)\n      {:noreply, state}\n    end\n    \n    @impl true\n    def handle_info({:expire, key}, state) do\n      :ets.delete(state.table, key)\n      state = Map.delete(state.ttl_timers, key)\n      {:noreply, state}\n    end\n    \n    defp get_from_cluster(key) do\n      members = :pg.get_members(@cache_group) -- [self()]\n      \n      members\n      |> Enum.map(&Task.async(fn ->\n        try do\n          GenServer.call(&1, {:get, key}, 1000)\n        catch\n          :exit, _ -> :not_found\n        end\n      end))\n      |> Enum.map(&Task.await(&1, 1000))\n      |> Enum.find(:not_found, &match?({:ok, _}, &1))\n    end\n    \n    defp cancel_ttl_timer(state, key) do\n      case Map.get(state.ttl_timers, key) do\n        nil -> state\n        timer_ref ->\n          Process.cancel_timer(timer_ref)\n          Map.delete(state.ttl_timers, key)\n      end\n    end\n  end\n  \n  # Distributed task execution with Horde\n  defmodule DistributedWorker do\n    use Horde.DynamicSupervisor\n    \n    def start_link(opts) do\n      Horde.DynamicSupervisor.start_link(__MODULE__, opts, name: __MODULE__)\n    end\n    \n    def start_job(job_spec) do\n      child_spec = %{\n        id: job_spec.id,\n        start: {JobWorker, :start_link, [job_spec]},\n        restart: :transient\n      }\n      \n      Horde.DynamicSupervisor.start_child(__MODULE__, child_spec)\n    end\n    \n    @impl true\n    def init(opts) do\n      Horde.DynamicSupervisor.init(\n        strategy: :one_for_one,\n        members: opts[:members] || :auto\n      )\n    end\n  end\n  \n  # Distributed registry using Horde\n  defmodule DistributedRegistry do\n    use Horde.Registry\n    \n    def start_link(opts) do\n      Horde.Registry.start_link(__MODULE__, opts, name: __MODULE__)\n    end\n    \n    def register(name, pid \\\\ self()) do\n      Horde.Registry.register(__MODULE__, name, pid)\n    end\n    \n    def lookup(name) do\n      case Horde.Registry.lookup(__MODULE__, name) do\n        [{pid, _}] -> {:ok, pid}\n        [] -> :error\n      end\n    end\n    \n    @impl true\n    def init(opts) do\n      Horde.Registry.init(\n        keys: :unique,\n        members: opts[:members] || :auto\n      )\n    end\n  end\n  \n  # Cluster formation using libcluster\n  defmodule ClusterManager do\n    use GenServer\n    \n    def start_link(opts) do\n      GenServer.start_link(__MODULE__, opts, name: __MODULE__)\n    end\n    \n    @impl true\n    def init(_opts) do\n      # Configure libcluster topologies\n      topologies = [\n        k8s: [\n          strategy: Cluster.Strategy.Kubernetes,\n          config: [\n            kubernetes_selector: \"app=myapp\",\n            kubernetes_namespace: \"default\"\n          ]\n        ],\n        gossip: [\n          strategy: Cluster.Strategy.Gossip,\n          config: [\n            port: 45892,\n            if_addr: \"0.0.0.0\",\n            multicast_addr: \"255.255.255.255\"\n          ]\n        ]\n      ]\n      \n      # Start the cluster supervisor\n      children = [\n        {Cluster.Supervisor, [topologies, [name: MyApp.ClusterSupervisor]]}\n      ]\n      \n      Supervisor.start_link(children, strategy: :one_for_one)\n      \n      {:ok, %{}}\n    end\n  end\nend"
    },
    "flow_based_processing": {
      "description": "Use GenStage and Flow for backpressure-aware data processing.",
      "whenToUse": "For processing large amounts of data with controlled resource usage.",
      "example": "defmodule DataProcessingPipeline do\n  # Producer - generates or fetches data\n  defmodule Producer do\n    use GenStage\n    \n    def start_link(opts) do\n      GenStage.start_link(__MODULE__, opts, name: __MODULE__)\n    end\n    \n    def init(opts) do\n      state = %{\n        counter: 0,\n        max_events: opts[:max_events] || :infinity,\n        source: opts[:source] || :counter\n      }\n      \n      {:producer, state}\n    end\n    \n    def handle_demand(demand, %{source: :counter} = state) when demand > 0 do\n      events = for i <- state.counter..(state.counter + demand - 1) do\n        %{id: i, data: \"event_#{i}\", timestamp: DateTime.utc_now()}\n      end\n      \n      new_counter = state.counter + demand\n      \n      if state.max_events != :infinity and new_counter >= state.max_events do\n        {:stop, :normal, events, state}\n      else\n        {:noreply, events, %{state | counter: new_counter}}\n      end\n    end\n    \n    def handle_demand(demand, %{source: {:file, path}} = state) do\n      # Read from file\n      events = path\n      |> File.stream!()\n      |> Stream.take(demand)\n      |> Enum.map(&parse_line/1)\n      |> Enum.to_list()\n      \n      if length(events) < demand do\n        {:stop, :normal, events, state}\n      else\n        {:noreply, events, state}\n      end\n    end\n    \n    defp parse_line(line) do\n      # Parse your data format\n      %{data: String.trim(line), timestamp: DateTime.utc_now()}\n    end\n  end\n  \n  # ProducerConsumer - transforms data\n  defmodule Transformer do\n    use GenStage\n    \n    def start_link(opts) do\n      GenStage.start_link(__MODULE__, opts, name: __MODULE__)\n    end\n    \n    def init(opts) do\n      subscribe_to = opts[:subscribe_to] || []\n      \n      {:producer_consumer, %{}, subscribe_to: subscribe_to}\n    end\n    \n    def handle_events(events, _from, state) do\n      transformed = Enum.map(events, &transform_event/1)\n      {:noreply, transformed, state}\n    end\n    \n    defp transform_event(event) do\n      # Add processing timestamp\n      event\n      |> Map.put(:processed_at, DateTime.utc_now())\n      |> Map.update!(:data, &process_data/1)\n    end\n    \n    defp process_data(data) do\n      # Your transformation logic\n      data\n      |> String.upcase()\n      |> String.replace(~r/[^A-Z0-9]/, \"_\")\n    end\n  end\n  \n  # Consumer - processes final data\n  defmodule Consumer do\n    use GenStage\n    \n    def start_link(opts) do\n      GenStage.start_link(__MODULE__, opts)\n    end\n    \n    def init(opts) do\n      subscribe_to = opts[:subscribe_to] || []\n      \n      state = %{\n        processed_count: 0,\n        batch_size: opts[:batch_size] || 100,\n        batch: []\n      }\n      \n      {:consumer, state, subscribe_to: subscribe_to}\n    end\n    \n    def handle_events(events, _from, state) do\n      # Add to batch\n      new_batch = state.batch ++ events\n      \n      if length(new_batch) >= state.batch_size do\n        # Process full batch\n        process_batch(new_batch)\n        \n        {:noreply, [], %{state | \n          batch: [],\n          processed_count: state.processed_count + length(new_batch)\n        }}\n      else\n        # Keep accumulating\n        {:noreply, [], %{state | batch: new_batch}}\n      end\n    end\n    \n    def handle_info(:flush, state) do\n      if length(state.batch) > 0 do\n        process_batch(state.batch)\n      end\n      \n      {:noreply, [], %{state | batch: []}}\n    end\n    \n    defp process_batch(batch) do\n      # Insert into database, send to external service, etc.\n      IO.puts(\"Processing batch of #{length(batch)} items\")\n      \n      # Simulate work\n      Process.sleep(100)\n    end\n  end\n  \n  # Flow-based pipeline for parallel processing\n  defmodule FlowPipeline do\n    def process_large_file(file_path, opts \\\\ []) do\n      window_size = opts[:window_size] || 1000\n      \n      file_path\n      |> File.stream!()\n      |> Flow.from_enumerable()\n      |> Flow.partition()\n      |> Flow.map(&parse_line/1)\n      |> Flow.filter(&valid_record?/1)\n      |> Flow.map(&transform_record/1)\n      |> Flow.group_by(&(&1.category))\n      |> Flow.reduce(fn -> %{} end, &aggregate/2)\n      |> Flow.emit(:state)\n      |> Enum.to_list()\n    end\n    \n    defp parse_line(line) do\n      line\n      |> String.split(\",\")\n      |> Enum.map(&String.trim/1)\n      |> to_record()\n    end\n    \n    defp to_record([id, category, value, timestamp]) do\n      %{\n        id: id,\n        category: category,\n        value: String.to_float(value),\n        timestamp: DateTime.from_iso8601!(timestamp)\n      }\n    end\n    \n    defp valid_record?(record) do\n      record.value > 0 and record.category != \"\"\n    end\n    \n    defp transform_record(record) do\n      %{record | \n        value: record.value * 1.1,  # Apply transformation\n        processed: true\n      }\n    end\n    \n    defp aggregate(record, acc) do\n      Map.update(acc, record.category, \n        %{count: 1, sum: record.value, records: [record]},\n        fn stats ->\n          %{stats | \n            count: stats.count + 1,\n            sum: stats.sum + record.value,\n            records: [record | stats.records]\n          }\n        end\n      )\n    end\n  end\n  \n  # Window-based processing with Flow\n  defmodule WindowedFlow do\n    def process_stream(stream) do\n      window = Flow.Window.global()\n      |> Flow.Window.trigger_every(1000, :reset)\n      \n      stream\n      |> Flow.from_enumerable()\n      |> Flow.partition(window: window, stages: 4)\n      |> Flow.reduce(fn -> %{} end, &count_events/2)\n      |> Flow.on_trigger(&emit_stats/1)\n      |> Flow.start_link()\n    end\n    \n    defp count_events(event, acc) do\n      Map.update(acc, event.type, 1, &(&1 + 1))\n    end\n    \n    defp emit_stats(acc) do\n      IO.inspect(acc, label: \"Window stats\")\n      \n      # Send to monitoring system\n      :telemetry.execute(\n        [:flow, :window, :complete],\n        %{events: Enum.sum(Map.values(acc))},\n        %{stats: acc}\n      )\n      \n      {[acc], %{}}\n    end\n  end\n  \n  # Broadway for robust data ingestion\n  defmodule DataIngestion do\n    use Broadway\n    \n    alias Broadway.Message\n    \n    def start_link(opts) do\n      Broadway.start_link(__MODULE__,\n        name: __MODULE__,\n        producer: [\n          module: {BroadwayRabbitMQ.Producer,\n            queue: \"data_ingestion\",\n            connection: [\n              host: opts[:rabbitmq_host] || \"localhost\"\n            ],\n            qos: [\n              prefetch_count: 50\n            ]\n          },\n          concurrency: 2\n        ],\n        processors: [\n          default: [\n            concurrency: 10,\n            min_demand: 5,\n            max_demand: 10\n          ]\n        ],\n        batchers: [\n          default: [\n            batch_size: 100,\n            batch_timeout: 1000,\n            concurrency: 5\n          ]\n        ]\n      )\n    end\n    \n    @impl true\n    def handle_message(_, %Message{data: data} = message, _) do\n      parsed = Jason.decode!(data)\n      \n      message\n      |> Message.update_data(&process_data/1)\n      |> Message.put_batch_key(parsed[\"type\"])\n    rescue\n      e ->\n        Message.failed(message, inspect(e))\n    end\n    \n    @impl true\n    def handle_batch(_, messages, batch_info, _) do\n      IO.puts(\"Batch #{batch_info.batch_key} with #{length(messages)} messages\")\n      \n      # Process batch\n      messages\n      |> Enum.map(&(&1.data))\n      |> MyApp.Database.bulk_insert()\n      \n      messages\n    end\n    \n    defp process_data(data) do\n      # Transform data\n      data\n    end\n  end\nend"
    }
  }
}