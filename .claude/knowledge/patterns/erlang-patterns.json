{
  "language": "erlang",
  "patterns": {
    "gen_server": {
      "description": "Implement server processes with state management and client-server communication.",
      "whenToUse": "For stateful processes that need to handle synchronous and asynchronous requests.",
      "example": "-module(counter_server).\n-behaviour(gen_server).\n\n%% API\n-export([start_link/0, start_link/1, increment/0, decrement/0, get_value/0, reset/0]).\n\n%% gen_server callbacks\n-export([init/1, handle_call/3, handle_cast/2, handle_info/2,\n         terminate/2, code_change/3]).\n\n-define(SERVER, ?MODULE).\n\n-record(state, {value = 0 :: integer()}).\n\n%%%===================================================================\n%%% API\n%%%===================================================================\n\nstart_link() ->\n    start_link(0).\n\nstart_link(InitialValue) ->\n    gen_server:start_link({local, ?SERVER}, ?MODULE, [InitialValue], []).\n\nincrement() ->\n    gen_server:call(?SERVER, increment).\n\ndecrement() ->\n    gen_server:call(?SERVER, decrement).\n\nget_value() ->\n    gen_server:call(?SERVER, get_value).\n\nreset() ->\n    gen_server:cast(?SERVER, reset).\n\n%%%===================================================================\n%%% gen_server callbacks\n%%%===================================================================\n\ninit([InitialValue]) ->\n    {ok, #state{value = InitialValue}}.\n\nhandle_call(increment, _From, State = #state{value = Value}) ->\n    NewValue = Value + 1,\n    {reply, NewValue, State#state{value = NewValue}};\nhandle_call(decrement, _From, State = #state{value = Value}) ->\n    NewValue = Value - 1,\n    {reply, NewValue, State#state{value = NewValue}};\nhandle_call(get_value, _From, State = #state{value = Value}) ->\n    {reply, Value, State};\nhandle_call(_Request, _From, State) ->\n    {reply, {error, unknown_request}, State}.\n\nhandle_cast(reset, State) ->\n    {noreply, State#state{value = 0}};\nhandle_cast(_Request, State) ->\n    {noreply, State}.\n\nhandle_info(_Info, State) ->\n    {noreply, State}.\n\nterminate(_Reason, _State) ->\n    ok.\n\ncode_change(_OldVsn, State, _Extra) ->\n    {ok, State}.\n\n%% Advanced gen_server with timeout and monitoring\n-module(session_manager).\n-behaviour(gen_server).\n\n-export([start_link/0, create_session/2, get_session/1, \n         refresh_session/1, delete_session/1]).\n-export([init/1, handle_call/3, handle_cast/2, handle_info/2]).\n\n-record(session, {\n    id :: binary(),\n    user_id :: term(),\n    data :: map(),\n    created :: erlang:timestamp(),\n    last_access :: erlang:timestamp(),\n    timeout_ref :: reference()\n}).\n\n-record(state, {\n    sessions = #{} :: #{binary() => #session{}},\n    timeout = 1800000 :: pos_integer()  % 30 minutes in ms\n}).\n\nstart_link() ->\n    gen_server:start_link({local, ?MODULE}, ?MODULE, [], []).\n\ncreate_session(UserId, Data) ->\n    gen_server:call(?MODULE, {create_session, UserId, Data}).\n\nget_session(SessionId) ->\n    gen_server:call(?MODULE, {get_session, SessionId}).\n\nrefresh_session(SessionId) ->\n    gen_server:call(?MODULE, {refresh_session, SessionId}).\n\ndelete_session(SessionId) ->\n    gen_server:cast(?MODULE, {delete_session, SessionId}).\n\ninit([]) ->\n    {ok, #state{}}.\n\nhandle_call({create_session, UserId, Data}, _From, State) ->\n    SessionId = generate_session_id(),\n    Now = erlang:timestamp(),\n    TimeoutRef = erlang:send_after(State#state.timeout, self(), \n                                   {timeout_session, SessionId}),\n    \n    Session = #session{\n        id = SessionId,\n        user_id = UserId,\n        data = Data,\n        created = Now,\n        last_access = Now,\n        timeout_ref = TimeoutRef\n    },\n    \n    NewSessions = maps:put(SessionId, Session, State#state.sessions),\n    {reply, {ok, SessionId}, State#state{sessions = NewSessions}};\n\nhandle_call({get_session, SessionId}, _From, State) ->\n    case maps:find(SessionId, State#state.sessions) of\n        {ok, Session} ->\n            %% Cancel old timeout and set new one\n            erlang:cancel_timer(Session#session.timeout_ref),\n            NewTimeoutRef = erlang:send_after(State#state.timeout, self(),\n                                             {timeout_session, SessionId}),\n            \n            UpdatedSession = Session#session{\n                last_access = erlang:timestamp(),\n                timeout_ref = NewTimeoutRef\n            },\n            \n            NewSessions = maps:put(SessionId, UpdatedSession, State#state.sessions),\n            {reply, {ok, UpdatedSession}, State#state{sessions = NewSessions}};\n        error ->\n            {reply, {error, not_found}, State}\n    end;\n\nhandle_call({refresh_session, SessionId}, _From, State) ->\n    %% Similar to get_session but doesn't return the session data\n    case maps:find(SessionId, State#state.sessions) of\n        {ok, Session} ->\n            erlang:cancel_timer(Session#session.timeout_ref),\n            NewTimeoutRef = erlang:send_after(State#state.timeout, self(),\n                                             {timeout_session, SessionId}),\n            \n            UpdatedSession = Session#session{\n                last_access = erlang:timestamp(),\n                timeout_ref = NewTimeoutRef\n            },\n            \n            NewSessions = maps:put(SessionId, UpdatedSession, State#state.sessions),\n            {reply, ok, State#state{sessions = NewSessions}};\n        error ->\n            {reply, {error, not_found}, State}\n    end.\n\nhandle_cast({delete_session, SessionId}, State) ->\n    case maps:find(SessionId, State#state.sessions) of\n        {ok, Session} ->\n            erlang:cancel_timer(Session#session.timeout_ref),\n            NewSessions = maps:remove(SessionId, State#state.sessions),\n            {noreply, State#state{sessions = NewSessions}};\n        error ->\n            {noreply, State}\n    end.\n\nhandle_info({timeout_session, SessionId}, State) ->\n    NewSessions = maps:remove(SessionId, State#state.sessions),\n    {noreply, State#state{sessions = NewSessions}}.\n\ngenerate_session_id() ->\n    base64:encode(crypto:strong_rand_bytes(32))."
    },
    "supervisor": {
      "description": "Build fault-tolerant supervision trees with automatic process restart.",
      "whenToUse": "For creating resilient systems that can recover from failures.",
      "example": "-module(my_supervisor).\n-behaviour(supervisor).\n\n%% API\n-export([start_link/0]).\n\n%% Supervisor callbacks\n-export([init/1]).\n\n-define(SERVER, ?MODULE).\n\nstart_link() ->\n    supervisor:start_link({local, ?SERVER}, ?MODULE, []).\n\ninit([]) ->\n    %% Restart strategy\n    SupFlags = #{\n        strategy => one_for_all,  % one_for_one | one_for_all | rest_for_one\n        intensity => 10,          % Max restarts\n        period => 60              % In this time period (seconds)\n    },\n    \n    %% Child specifications\n    ChildSpecs = [\n        #{\n            id => counter_server,\n            start => {counter_server, start_link, []},\n            restart => permanent,  % permanent | temporary | transient\n            shutdown => 5000,      % Shutdown timeout or brutal_kill\n            type => worker,        % worker | supervisor\n            modules => [counter_server]\n        },\n        #{\n            id => cache_server,\n            start => {cache_server, start_link, [[{ttl, 3600}]]},\n            restart => permanent,\n            shutdown => 5000,\n            type => worker,\n            modules => [cache_server]\n        },\n        #{\n            id => worker_sup,\n            start => {worker_supervisor, start_link, []},\n            restart => permanent,\n            shutdown => infinity,  % For supervisors\n            type => supervisor,\n            modules => [worker_supervisor]\n        }\n    ],\n    \n    {ok, {SupFlags, ChildSpecs}}.\n\n%% Dynamic supervisor for on-demand workers\n-module(worker_supervisor).\n-behaviour(supervisor).\n\n-export([start_link/0, start_worker/1, stop_worker/1]).\n-export([init/1]).\n\nstart_link() ->\n    supervisor:start_link({local, ?MODULE}, ?MODULE, []).\n\nstart_worker(Args) ->\n    ChildSpec = #{\n        id => make_ref(),  % Unique ID\n        start => {worker, start_link, [Args]},\n        restart => temporary,\n        shutdown => 5000,\n        type => worker,\n        modules => [worker]\n    },\n    supervisor:start_child(?MODULE, ChildSpec).\n\nstop_worker(Pid) when is_pid(Pid) ->\n    supervisor:terminate_child(?MODULE, Pid),\n    supervisor:delete_child(?MODULE, Pid).\n\ninit([]) ->\n    %% Simple one-for-one is deprecated in favor of DynamicSupervisor\n    %% but still works for dynamic children\n    SupFlags = #{\n        strategy => one_for_one,\n        intensity => 10,\n        period => 60\n    },\n    \n    {ok, {SupFlags, []}}.\n\n%% Application supervisor with different restart strategies\n-module(app_supervisor).\n-behaviour(supervisor).\n\n-export([start_link/0]).\n-export([init/1]).\n\nstart_link() ->\n    supervisor:start_link({local, ?MODULE}, ?MODULE, []).\n\ninit([]) ->\n    SupFlags = #{strategy => one_for_one, intensity => 10, period => 60},\n    \n    ChildSpecs = [\n        %% Database connection pool - all workers depend on this\n        %% Use rest_for_one so workers restart if DB restarts\n        #{\n            id => db_supervisor,\n            start => {supervisor, start_link, [\n                {local, db_sup},\n                ?MODULE,\n                [db_pool]\n            ]},\n            restart => permanent,\n            shutdown => infinity,\n            type => supervisor,\n            modules => [?MODULE]\n        },\n        \n        %% Cache and session managers - independent\n        %% Use one_for_one strategy\n        #{\n            id => service_supervisor,\n            start => {supervisor, start_link, [\n                {local, service_sup},\n                ?MODULE,\n                [services]\n            ]},\n            restart => permanent,\n            shutdown => infinity,\n            type => supervisor,\n            modules => [?MODULE]\n        }\n    ],\n    \n    {ok, {SupFlags, ChildSpecs}};\n\ninit([db_pool]) ->\n    %% Database pool with rest_for_one\n    SupFlags = #{strategy => rest_for_one, intensity => 5, period => 60},\n    \n    ChildSpecs = [\n        #{\n            id => db_connection,\n            start => {db_connection, start_link, []},\n            restart => permanent,\n            shutdown => 5000,\n            type => worker,\n            modules => [db_connection]\n        },\n        #{\n            id => db_pool_manager,\n            start => {db_pool_manager, start_link, []},\n            restart => permanent,\n            shutdown => 5000,\n            type => worker,\n            modules => [db_pool_manager]\n        }\n    ],\n    \n    {ok, {SupFlags, ChildSpecs}};\n\ninit([services]) ->\n    %% Independent services with one_for_one\n    SupFlags = #{strategy => one_for_one, intensity => 10, period => 60},\n    \n    ChildSpecs = [\n        #{\n            id => cache_server,\n            start => {cache_server, start_link, []},\n            restart => permanent,\n            shutdown => 5000,\n            type => worker,\n            modules => [cache_server]\n        },\n        #{\n            id => session_manager,\n            start => {session_manager, start_link, []},\n            restart => permanent,\n            shutdown => 5000,\n            type => worker,\n            modules => [session_manager]\n        }\n    ],\n    \n    {ok, {SupFlags, ChildSpecs}}."
    },
    "service_worker": {
      "description": "Implement the service-worker pattern for managing pools of workers.",
      "whenToUse": "For load distribution and parallel processing with worker pools.",
      "example": "%% Service manager that coordinates workers\n-module(task_service).\n-behaviour(gen_server).\n\n-export([start_link/0, submit_task/1, get_stats/0]).\n-export([init/1, handle_call/3, handle_cast/2, handle_info/2]).\n\n-record(state, {\n    workers = [] :: [pid()],\n    pending = queue:new() :: queue:queue(),\n    busy = #{} :: #{pid() => term()},\n    completed = 0 :: non_neg_integer(),\n    failed = 0 :: non_neg_integer()\n}).\n\nstart_link() ->\n    gen_server:start_link({local, ?MODULE}, ?MODULE, [], []).\n\nsubmit_task(Task) ->\n    gen_server:call(?MODULE, {submit_task, Task}).\n\nget_stats() ->\n    gen_server:call(?MODULE, get_stats).\n\ninit([]) ->\n    %% Start worker supervisor\n    {ok, _} = task_worker_sup:start_link(),\n    \n    %% Start initial workers\n    Workers = [start_worker() || _ <- lists:seq(1, 5)],\n    \n    {ok, #state{workers = Workers}}.\n\nhandle_call({submit_task, Task}, From, State) ->\n    %% Find available worker\n    case find_available_worker(State) of\n        {ok, Worker} ->\n            %% Assign task to worker\n            Worker ! {task, self(), Task},\n            NewBusy = maps:put(Worker, {Task, From}, State#state.busy),\n            {noreply, State#state{busy = NewBusy}};\n        \n        {error, all_busy} ->\n            %% Queue the task\n            NewPending = queue:in({Task, From}, State#state.pending),\n            {noreply, State#state{pending = NewPending}}\n    end;\n\nhandle_call(get_stats, _From, State) ->\n    Stats = #{\n        workers => length(State#state.workers),\n        busy => maps:size(State#state.busy),\n        pending => queue:len(State#state.pending),\n        completed => State#state.completed,\n        failed => State#state.failed\n    },\n    {reply, Stats, State}.\n\nhandle_cast(_Request, State) ->\n    {noreply, State}.\n\nhandle_info({task_complete, Worker, Result}, State) ->\n    %% Worker completed task\n    case maps:find(Worker, State#state.busy) of\n        {ok, {_Task, From}} ->\n            %% Reply to client\n            gen_server:reply(From, {ok, Result}),\n            \n            %% Update state\n            NewBusy = maps:remove(Worker, State#state.busy),\n            NewState = State#state{\n                busy = NewBusy,\n                completed = State#state.completed + 1\n            },\n            \n            %% Check for pending tasks\n            case queue:out(NewState#state.pending) of\n                {{value, {Task, NextFrom}}, NewPending} ->\n                    %% Assign pending task to available worker\n                    Worker ! {task, self(), Task},\n                    NewBusy2 = maps:put(Worker, {Task, NextFrom}, NewBusy),\n                    {noreply, NewState#state{\n                        pending = NewPending,\n                        busy = NewBusy2\n                    }};\n                \n                {empty, _} ->\n                    {noreply, NewState}\n            end;\n        \n        error ->\n            {noreply, State}\n    end;\n\nhandle_info({task_failed, Worker, Reason}, State) ->\n    %% Worker failed to complete task\n    case maps:find(Worker, State#state.busy) of\n        {ok, {_Task, From}} ->\n            %% Reply with error\n            gen_server:reply(From, {error, Reason}),\n            \n            %% Update state\n            NewBusy = maps:remove(Worker, State#state.busy),\n            NewState = State#state{\n                busy = NewBusy,\n                failed = State#state.failed + 1\n            },\n            \n            %% Restart worker\n            exit(Worker, kill),\n            NewWorker = start_worker(),\n            Workers = [NewWorker | lists:delete(Worker, State#state.workers)],\n            \n            {noreply, NewState#state{workers = Workers}};\n        \n        error ->\n            {noreply, State}\n    end;\n\nhandle_info({'DOWN', _Ref, process, Worker, _Reason}, State) ->\n    %% Worker crashed\n    NewWorker = start_worker(),\n    Workers = [NewWorker | lists:delete(Worker, State#state.workers)],\n    \n    %% Handle any task that was being processed\n    case maps:find(Worker, State#state.busy) of\n        {ok, {Task, From}} ->\n            %% Re-queue the task\n            NewPending = queue:in_r({Task, From}, State#state.pending),\n            NewBusy = maps:remove(Worker, State#state.busy),\n            \n            {noreply, State#state{\n                workers = Workers,\n                pending = NewPending,\n                busy = NewBusy\n            }};\n        \n        error ->\n            {noreply, State#state{workers = Workers}}\n    end.\n\nfind_available_worker(#state{workers = Workers, busy = Busy}) ->\n    Available = [W || W <- Workers, not maps:is_key(W, Busy)],\n    case Available of\n        [Worker | _] -> {ok, Worker};\n        [] -> {error, all_busy}\n    end.\n\nstart_worker() ->\n    {ok, Pid} = task_worker_sup:start_worker(),\n    erlang:monitor(process, Pid),\n    Pid.\n\n%% Worker module\n-module(task_worker).\n\n-export([start_link/0, init/0]).\n\nstart_link() ->\n    proc_lib:start_link(?MODULE, init, []).\n\ninit() ->\n    proc_lib:init_ack({ok, self()}),\n    worker_loop().\n\nworker_loop() ->\n    receive\n        {task, Service, Task} ->\n            %% Process task\n            try\n                Result = process_task(Task),\n                Service ! {task_complete, self(), Result}\n            catch\n                _:Reason ->\n                    Service ! {task_failed, self(), Reason}\n            end,\n            worker_loop();\n        \n        stop ->\n            ok\n    end.\n\nprocess_task(Task) ->\n    %% Simulate work\n    timer:sleep(rand:uniform(1000)),\n    \n    %% Random failure for demonstration\n    case rand:uniform(10) of\n        1 -> error(random_failure);\n        _ -> {processed, Task}\n    end.\n\n%% Worker supervisor\n-module(task_worker_sup).\n-behaviour(supervisor).\n\n-export([start_link/0, start_worker/0]).\n-export([init/1]).\n\nstart_link() ->\n    supervisor:start_link({local, ?MODULE}, ?MODULE, []).\n\nstart_worker() ->\n    supervisor:start_child(?MODULE, []).\n\ninit([]) ->\n    SupFlags = #{strategy => simple_one_for_one, intensity => 10, period => 60},\n    \n    ChildSpec = #{\n        id => task_worker,\n        start => {task_worker, start_link, []},\n        restart => temporary,\n        shutdown => 5000,\n        type => worker,\n        modules => [task_worker]\n    },\n    \n    {ok, {SupFlags, [ChildSpec]}}."
    },
    "event_handler": {
      "description": "Use gen_event for implementing event handling and notification systems.",
      "whenToUse": "For publish-subscribe patterns and event-driven architectures.",
      "example": "%% Event manager\n-module(app_events).\n\n-export([start_link/0, add_handler/2, delete_handler/2,\n         notify/1, sync_notify/1]).\n\nstart_link() ->\n    gen_event:start_link({local, ?MODULE}).\n\nadd_handler(Handler, Args) ->\n    gen_event:add_handler(?MODULE, Handler, Args).\n\ndelete_handler(Handler, Args) ->\n    gen_event:delete_handler(?MODULE, Handler, Args).\n\nnotify(Event) ->\n    gen_event:notify(?MODULE, Event).\n\nsync_notify(Event) ->\n    gen_event:sync_notify(?MODULE, Event).\n\n%% Event handler for logging\n-module(log_handler).\n-behaviour(gen_event).\n\n-export([init/1, handle_event/2, handle_call/2, handle_info/2,\n         terminate/2, code_change/3]).\n\n-record(state, {\n    log_file :: file:io_device(),\n    level :: debug | info | warning | error\n}).\n\ninit([{file, FileName}, {level, Level}]) ->\n    case file:open(FileName, [append, {encoding, utf8}]) of\n        {ok, File} ->\n            {ok, #state{log_file = File, level = Level}};\n        {error, Reason} ->\n            {error, Reason}\n    end.\n\nhandle_event({log, Level, Message}, State) ->\n    case should_log(Level, State#state.level) of\n        true ->\n            Timestamp = calendar:local_time(),\n            io:format(State#state.log_file, \"~p [~p] ~s~n\",\n                     [Timestamp, Level, Message]);\n        false ->\n            ok\n    end,\n    {ok, State};\n\nhandle_event({user_action, Action, UserId}, State) ->\n    Message = io_lib:format(\"User ~p performed action: ~p\", [UserId, Action]),\n    handle_event({log, info, Message}, State);\n\nhandle_event(_Event, State) ->\n    {ok, State}.\n\nhandle_call(get_stats, State) ->\n    %% Could return logging statistics\n    {ok, {stats, []}, State};\n\nhandle_call(_Request, State) ->\n    {ok, {error, unknown_request}, State}.\n\nhandle_info(_Info, State) ->\n    {ok, State}.\n\nterminate(_Reason, State) ->\n    file:close(State#state.log_file),\n    ok.\n\ncode_change(_OldVsn, State, _Extra) ->\n    {ok, State}.\n\nshould_log(MessageLevel, ConfigLevel) ->\n    level_to_int(MessageLevel) >= level_to_int(ConfigLevel).\n\nlevel_to_int(debug) -> 0;\nlevel_to_int(info) -> 1;\nlevel_to_int(warning) -> 2;\nlevel_to_int(error) -> 3.\n\n%% Metrics handler\n-module(metrics_handler).\n-behaviour(gen_event).\n\n-export([init/1, handle_event/2, handle_call/2]).\n\n-record(state, {\n    counters = #{} :: #{atom() => integer()},\n    gauges = #{} :: #{atom() => number()},\n    histograms = #{} :: #{atom() => [number()]}\n}).\n\ninit([]) ->\n    {ok, #state{}}.\n\nhandle_event({counter, Name, Increment}, State) ->\n    Counters = maps:update_with(Name, fun(V) -> V + Increment end,\n                               Increment, State#state.counters),\n    {ok, State#state{counters = Counters}};\n\nhandle_event({gauge, Name, Value}, State) ->\n    Gauges = maps:put(Name, Value, State#state.gauges),\n    {ok, State#state{gauges = Gauges}};\n\nhandle_event({timing, Name, Duration}, State) ->\n    Histograms = maps:update_with(\n        Name,\n        fun(List) -> [Duration | lists:sublist(List, 999)] end,\n        [Duration],\n        State#state.histograms\n    ),\n    {ok, State#state{histograms = Histograms}};\n\nhandle_event(_Event, State) ->\n    {ok, State}.\n\nhandle_call(get_metrics, State) ->\n    Metrics = #{\n        counters => State#state.counters,\n        gauges => State#state.gauges,\n        histograms => calculate_histogram_stats(State#state.histograms)\n    },\n    {ok, Metrics, State};\n\nhandle_call({get_metric, Type, Name}, State) ->\n    Value = case Type of\n        counter -> maps:get(Name, State#state.counters, 0);\n        gauge -> maps:get(Name, State#state.gauges, undefined);\n        histogram -> \n            case maps:find(Name, State#state.histograms) of\n                {ok, Values} -> calculate_stats(Values);\n                error -> undefined\n            end\n    end,\n    {ok, Value, State}.\n\ncalculate_histogram_stats(Histograms) ->\n    maps:map(fun(_Name, Values) -> calculate_stats(Values) end, Histograms).\n\ncalculate_stats([]) ->\n    #{count => 0, mean => 0, min => 0, max => 0, p50 => 0, p95 => 0, p99 => 0};\ncalculate_stats(Values) ->\n    Sorted = lists:sort(Values),\n    Count = length(Sorted),\n    #{\n        count => Count,\n        mean => lists:sum(Sorted) / Count,\n        min => hd(Sorted),\n        max => lists:last(Sorted),\n        p50 => percentile(Sorted, 0.50),\n        p95 => percentile(Sorted, 0.95),\n        p99 => percentile(Sorted, 0.99)\n    }.\n\npercentile(Sorted, P) ->\n    K = (length(Sorted) - 1) * P + 1,\n    F = floor(K),\n    C = ceiling(K),\n    \n    case F == C of\n        true -> lists:nth(round(K), Sorted);\n        false ->\n            M0 = lists:nth(round(F), Sorted),\n            M1 = lists:nth(round(C), Sorted),\n            M0 + (M1 - M0) * (K - F)\n    end.\n\nfloor(X) -> trunc(X).\nceiling(X) when X == trunc(X) -> X;\nceiling(X) -> trunc(X) + 1."
    },
    "fsm": {
      "description": "Implement finite state machines using gen_statem for complex state transitions.",
      "whenToUse": "For modeling systems with well-defined states and transitions.",
      "example": "%% Door lock FSM using gen_statem\n-module(door_lock).\n-behaviour(gen_statem).\n\n-export([start_link/1, button/1, code_length/0]).\n-export([init/1, callback_mode/0, terminate/3]).\n-export([locked/3, open/3]).\n\n-define(CODE_LENGTH, 4).\n\nstart_link(Code) when length(Code) =:= ?CODE_LENGTH ->\n    gen_statem:start_link({local, ?MODULE}, ?MODULE, Code, []).\n\nbutton(Button) ->\n    gen_statem:cast(?MODULE, {button, Button}).\n\ncode_length() ->\n    ?CODE_LENGTH.\n\n%% gen_statem callbacks\ninit(Code) ->\n    Data = #{code => Code, remaining => Code, buttons => []},\n    {ok, locked, Data}.\n\ncallback_mode() ->\n    state_functions.\n\n%% State: locked\nlocked(cast, {button, Button}, #{code := Code, remaining := Remaining} = Data) ->\n    case Remaining of\n        [Button | Rest] ->\n            %% Correct button\n            case Rest of\n                [] ->\n                    %% Complete code entered\n                    io:format(\"Correct code! Door opening...~n\"),\n                    {next_state, open, Data#{remaining := Code},\n                     [{state_timeout, 5000, lock}]};\n                _ ->\n                    %% Partial code\n                    {keep_state, Data#{remaining := Rest}}\n            end;\n        _ ->\n            %% Wrong button - reset\n            io:format(\"Wrong code!~n\"),\n            {keep_state, Data#{remaining := Code}}\n    end;\n\nlocked(EventType, EventContent, Data) ->\n    handle_common(EventType, EventContent, Data).\n\n%% State: open\nopen(state_timeout, lock, Data) ->\n    io:format(\"Door closing...~n\"),\n    {next_state, locked, Data};\n\nopen(cast, {button, _Button}, Data) ->\n    %% Ignore buttons while open\n    {keep_state, Data};\n\nopen(EventType, EventContent, Data) ->\n    handle_common(EventType, EventContent, Data).\n\n%% Common event handler\nhandle_common({call, From}, get_state, Data) ->\n    {keep_state, Data, [{reply, From, {state_name(), Data}}]};\n\nhandle_common(_, _, _) ->\n    keep_state_and_data.\n\nterminate(_Reason, _State, _Data) ->\n    ok.\n\n%% Connection FSM with timeouts and retries\n-module(connection_fsm).\n-behaviour(gen_statem).\n\n-export([start_link/1, connect/0, disconnect/0, send_data/1]).\n-export([init/1, callback_mode/0]).\n-export([disconnected/3, connecting/3, connected/3]).\n\n-record(data, {\n    server :: {inet:ip_address(), inet:port_number()},\n    socket :: gen_tcp:socket() | undefined,\n    retry_count = 0 :: non_neg_integer(),\n    max_retries = 3 :: non_neg_integer(),\n    retry_delay = 1000 :: pos_integer()\n}).\n\nstart_link(Server) ->\n    gen_statem:start_link({local, ?MODULE}, ?MODULE, Server, []).\n\nconnect() ->\n    gen_statem:call(?MODULE, connect).\n\ndisconnect() ->\n    gen_statem:call(?MODULE, disconnect).\n\nsend_data(Data) ->\n    gen_statem:call(?MODULE, {send, Data}).\n\ninit({Host, Port}) ->\n    Data = #data{server = {Host, Port}},\n    {ok, disconnected, Data}.\n\ncallback_mode() ->\n    [state_functions, state_enter].\n\n%% State: disconnected\ndisconnected(enter, _OldState, Data) ->\n    %% Reset retry count when entering disconnected state\n    {keep_state, Data#data{retry_count = 0}};\n\ndisconnected({call, From}, connect, Data) ->\n    %% Start connection attempt\n    {next_state, connecting, Data, [{reply, From, ok}]};\n\ndisconnected({call, From}, disconnect, Data) ->\n    {keep_state, Data, [{reply, From, {error, not_connected}}]};\n\ndisconnected({call, From}, {send, _Data}, _Data) ->\n    {keep_state_and_data, [{reply, From, {error, not_connected}}]}.\n\n%% State: connecting\nconnecting(enter, _OldState, #data{server = {Host, Port}} = Data) ->\n    %% Attempt to connect\n    case gen_tcp:connect(Host, Port, [binary, {active, true}], 5000) of\n        {ok, Socket} ->\n            {next_state, connected, Data#data{socket = Socket}};\n        {error, Reason} ->\n            handle_connection_failure(Reason, Data)\n    end;\n\nconnecting({call, From}, connect, Data) ->\n    %% Already connecting\n    {keep_state, Data, [{reply, From, {error, already_connecting}}]};\n\nconnecting({call, From}, _, Data) ->\n    {keep_state, Data, [{reply, From, {error, connecting}}]}.\n\n%% State: connected\nconnected(enter, _OldState, Data) ->\n    io:format(\"Connected successfully!~n\"),\n    %% Reset retry count on successful connection\n    {keep_state, Data#data{retry_count = 0}};\n\nconnected({call, From}, disconnect, #data{socket = Socket} = Data) ->\n    gen_tcp:close(Socket),\n    {next_state, disconnected, Data#data{socket = undefined},\n     [{reply, From, ok}]};\n\nconnected({call, From}, {send, Payload}, #data{socket = Socket} = Data) ->\n    case gen_tcp:send(Socket, Payload) of\n        ok ->\n            {keep_state, Data, [{reply, From, ok}]};\n        {error, Reason} ->\n            gen_tcp:close(Socket),\n            {next_state, disconnected, Data#data{socket = undefined},\n             [{reply, From, {error, Reason}}]}\n    end;\n\nconnected(info, {tcp_closed, Socket}, #data{socket = Socket} = Data) ->\n    io:format(\"Connection closed by peer~n\"),\n    {next_state, disconnected, Data#data{socket = undefined}};\n\nconnected(info, {tcp_error, Socket, Reason}, #data{socket = Socket} = Data) ->\n    io:format(\"Connection error: ~p~n\", [Reason]),\n    gen_tcp:close(Socket),\n    {next_state, disconnected, Data#data{socket = undefined}};\n\nconnected(info, {tcp, Socket, Data}, #data{socket = Socket} = State) ->\n    io:format(\"Received data: ~p~n\", [Data]),\n    {keep_state, State}.\n\n%% Helper functions\nhandle_connection_failure(Reason, #data{retry_count = Count,\n                                       max_retries = Max,\n                                       retry_delay = Delay} = Data) ->\n    io:format(\"Connection failed: ~p (attempt ~p/~p)~n\",\n              [Reason, Count + 1, Max]),\n    \n    if\n        Count < Max ->\n            %% Schedule retry\n            {keep_state, Data#data{retry_count = Count + 1},\n             [{state_timeout, Delay * (Count + 1), retry}]};\n        true ->\n            %% Max retries reached\n            {next_state, disconnected, Data}\n    end."
    },
    "distributed_erlang": {
      "description": "Build distributed systems using Erlang's built-in distribution features.",
      "whenToUse": "For creating fault-tolerant distributed applications.",
      "example": "%% Distributed registry\n-module(dist_registry).\n-behaviour(gen_server).\n\n-export([start_link/0, register_name/2, unregister_name/1,\n         whereis_name/1, registered/0]).\n-export([init/1, handle_call/3, handle_cast/2, handle_info/2]).\n\n-record(state, {\n    registrations = #{} :: #{atom() => {pid(), node()}},\n    monitors = #{} :: #{reference() => atom()}\n}).\n\nstart_link() ->\n    gen_server:start_link({local, ?MODULE}, ?MODULE, [], []).\n\nregister_name(Name, Pid) ->\n    gen_server:call(?MODULE, {register, Name, Pid}).\n\nunregister_name(Name) ->\n    gen_server:call(?MODULE, {unregister, Name}).\n\nwhereis_name(Name) ->\n    gen_server:call(?MODULE, {whereis, Name}).\n\nregistered() ->\n    gen_server:call(?MODULE, registered).\n\ninit([]) ->\n    %% Subscribe to node events\n    net_kernel:monitor_nodes(true),\n    \n    %% Sync with other nodes\n    case nodes() of\n        [] -> ok;\n        Nodes -> sync_with_nodes(Nodes)\n    end,\n    \n    {ok, #state{}}.\n\nhandle_call({register, Name, Pid}, _From, State) ->\n    case maps:find(Name, State#state.registrations) of\n        error ->\n            %% Monitor the process\n            Ref = erlang:monitor(process, Pid),\n            \n            %% Broadcast registration to other nodes\n            broadcast({register, Name, Pid, node()}, State),\n            \n            %% Update local state\n            NewRegs = maps:put(Name, {Pid, node(Pid)}, State#state.registrations),\n            NewMons = maps:put(Ref, Name, State#state.monitors),\n            \n            {reply, ok, State#state{registrations = NewRegs, monitors = NewMons}};\n        \n        {ok, {OldPid, _}} ->\n            {reply, {error, {already_registered, OldPid}}, State}\n    end;\n\nhandle_call({unregister, Name}, _From, State) ->\n    case maps:find(Name, State#state.registrations) of\n        {ok, {Pid, _Node}} ->\n            %% Find and remove monitor\n            Ref = find_monitor_by_name(Name, State#state.monitors),\n            erlang:demonitor(Ref, [flush]),\n            \n            %% Broadcast unregistration\n            broadcast({unregister, Name}, State),\n            \n            %% Update state\n            NewRegs = maps:remove(Name, State#state.registrations),\n            NewMons = maps:remove(Ref, State#state.monitors),\n            \n            {reply, ok, State#state{registrations = NewRegs, monitors = NewMons}};\n        \n        error ->\n            {reply, {error, not_registered}, State}\n    end;\n\nhandle_call({whereis, Name}, _From, State) ->\n    case maps:find(Name, State#state.registrations) of\n        {ok, {Pid, _Node}} -> {reply, Pid, State};\n        error -> {reply, undefined, State}\n    end;\n\nhandle_call(registered, _From, State) ->\n    Names = maps:keys(State#state.registrations),\n    {reply, Names, State}.\n\nhandle_cast({remote_register, Name, Pid, Node}, State) ->\n    %% Registration from another node\n    case maps:find(Name, State#state.registrations) of\n        error ->\n            %% Monitor remote process\n            Ref = erlang:monitor(process, Pid),\n            NewRegs = maps:put(Name, {Pid, Node}, State#state.registrations),\n            NewMons = maps:put(Ref, Name, State#state.monitors),\n            {noreply, State#state{registrations = NewRegs, monitors = NewMons}};\n        \n        {ok, _} ->\n            %% Already registered locally, ignore\n            {noreply, State}\n    end;\n\nhandle_cast({remote_unregister, Name}, State) ->\n    %% Unregistration from another node\n    case maps:find(Name, State#state.registrations) of\n        {ok, {_Pid, _Node}} ->\n            Ref = find_monitor_by_name(Name, State#state.monitors),\n            erlang:demonitor(Ref, [flush]),\n            \n            NewRegs = maps:remove(Name, State#state.registrations),\n            NewMons = maps:remove(Ref, State#state.monitors),\n            {noreply, State#state{registrations = NewRegs, monitors = NewMons}};\n        \n        error ->\n            {noreply, State}\n    end.\n\nhandle_info({'DOWN', Ref, process, _Pid, _Reason}, State) ->\n    %% Process died\n    case maps:find(Ref, State#state.monitors) of\n        {ok, Name} ->\n            %% Broadcast unregistration\n            broadcast({unregister, Name}, State),\n            \n            %% Update state\n            NewRegs = maps:remove(Name, State#state.registrations),\n            NewMons = maps:remove(Ref, State#state.monitors),\n            {noreply, State#state{registrations = NewRegs, monitors = NewMons}};\n        \n        error ->\n            {noreply, State}\n    end;\n\nhandle_info({nodedown, Node}, State) ->\n    %% Remove all registrations from the down node\n    {RegsToKeep, RegsToRemove} = maps:partition(\n        fun(_Name, {_Pid, PidNode}) -> PidNode =/= Node end,\n        State#state.registrations\n    ),\n    \n    %% Remove monitors for removed registrations\n    MonsToKeep = maps:filter(\n        fun(Ref, Name) ->\n            maps:is_key(Name, RegsToKeep)\n        end,\n        State#state.monitors\n    ),\n    \n    %% Demonitor removed processes\n    maps:foreach(\n        fun(Ref, _Name) ->\n            case maps:is_key(Ref, MonsToKeep) of\n                false -> erlang:demonitor(Ref, [flush]);\n                true -> ok\n            end\n        end,\n        State#state.monitors\n    ),\n    \n    {noreply, State#state{registrations = RegsToKeep, monitors = MonsToKeep}};\n\nhandle_info({nodeup, Node}, State) ->\n    %% New node joined, sync our state\n    gen_server:cast({?MODULE, Node}, {sync_request, self()}),\n    {noreply, State};\n\nhandle_info({sync_data, Registrations}, State) ->\n    %% Merge registrations from another node\n    NewState = maps:fold(\n        fun(Name, {Pid, Node}, AccState) ->\n            case maps:find(Name, AccState#state.registrations) of\n                error ->\n                    %% Add new registration\n                    Ref = erlang:monitor(process, Pid),\n                    AccState#state{\n                        registrations = maps:put(Name, {Pid, Node},\n                                               AccState#state.registrations),\n                        monitors = maps:put(Ref, Name, AccState#state.monitors)\n                    };\n                {ok, _} ->\n                    %% Already have this registration\n                    AccState\n            end\n        end,\n        State,\n        Registrations\n    ),\n    {noreply, NewState}.\n\nbroadcast({register, Name, Pid, Node}, _State) ->\n    [gen_server:cast({?MODULE, N}, {remote_register, Name, Pid, Node})\n     || N <- nodes()];\n\nbroadcast({unregister, Name}, _State) ->\n    [gen_server:cast({?MODULE, N}, {remote_unregister, Name})\n     || N <- nodes()].\n\nfind_monitor_by_name(Name, Monitors) ->\n    maps:fold(\n        fun(Ref, MonName, Acc) ->\n            case MonName of\n                Name -> Ref;\n                _ -> Acc\n            end\n        end,\n        undefined,\n        Monitors\n    ).\n\nsync_with_nodes(Nodes) ->\n    [gen_server:cast({?MODULE, Node}, {sync_request, self()})\n     || Node <- Nodes].\n\n%% Distributed task execution\n-module(dist_task).\n\n-export([execute/2, execute_on_all/1, execute_on_node/2]).\n\nexecute(Fun, Args) when is_function(Fun) ->\n    %% Execute on least loaded node\n    Node = select_node(),\n    execute_on_node(Node, fun() -> apply(Fun, Args) end).\n\nexecute_on_all(Fun) when is_function(Fun, 0) ->\n    Nodes = [node() | nodes()],\n    Tasks = [async_execute_on_node(N, Fun) || N <- Nodes],\n    [receive_result(T) || T <- Tasks].\n\nexecute_on_node(Node, Fun) when is_function(Fun, 0) ->\n    case Node of\n        Node when Node =:= node() ->\n            %% Local execution\n            try\n                {ok, Fun()}\n            catch\n                Class:Reason:Stack ->\n                    {error, {Class, Reason, Stack}}\n            end;\n        \n        _ ->\n            %% Remote execution\n            Ref = make_ref(),\n            {?MODULE, Node} ! {execute, self(), Ref, Fun},\n            \n            receive\n                {result, Ref, Result} -> Result\n            after 30000 ->\n                {error, timeout}\n            end\n    end.\n\nasync_execute_on_node(Node, Fun) ->\n    Ref = make_ref(),\n    Pid = spawn(fun() ->\n        Result = execute_on_node(Node, Fun),\n        exit({Ref, Result})\n    end),\n    {Ref, Pid}.\n\nreceive_result({Ref, Pid}) ->\n    receive\n        {'EXIT', Pid, {Ref, Result}} -> Result\n    after 30000 ->\n        exit(Pid, kill),\n        {error, timeout}\n    end.\n\nselect_node() ->\n    %% Simple round-robin selection\n    Nodes = [node() | nodes()],\n    Index = erlang:phash2(self(), length(Nodes)) + 1,\n    lists:nth(Index, Nodes)."
    },
    "error_kernel": {
      "description": "Build error kernels for isolating failures and maintaining system stability.",
      "whenToUse": "For critical system components that must remain stable.",
      "example": "%% Error kernel pattern - minimal, trusted code\n-module(system_kernel).\n-behaviour(gen_server).\n\n%% This module should be as simple as possible\n%% and thoroughly tested. It's the stable core\n%% that manages less stable components.\n\n-export([start_link/0, register_component/2, component_crashed/1]).\n-export([init/1, handle_call/3, handle_cast/2, handle_info/2]).\n\n-record(component, {\n    name :: atom(),\n    type :: critical | normal | expendable,\n    restarts = 0 :: non_neg_integer(),\n    last_crash :: undefined | erlang:timestamp()\n}).\n\n-record(state, {\n    components = #{} :: #{pid() => #component{}},\n    policies = #{} :: #{atom() => fun((#component{}) -> restart | stop)}\n}).\n\nstart_link() ->\n    gen_server:start_link({local, ?MODULE}, ?MODULE, [], []).\n\nregister_component(Name, Type) ->\n    gen_server:call(?MODULE, {register, self(), Name, Type}).\n\ncomponent_crashed(Pid) ->\n    gen_server:cast(?MODULE, {crashed, Pid}).\n\n%% Minimal init - just set up the basic state\ninit([]) ->\n    process_flag(trap_exit, true),\n    \n    Policies = #{\n        critical => fun(_) -> restart end,\n        normal => fun(#component{restarts = R}) when R < 3 -> restart;\n                     (_) -> stop\n                  end,\n        expendable => fun(_) -> stop end\n    },\n    \n    {ok, #state{policies = Policies}}.\n\n%% Keep handlers simple and defensive\nhandle_call({register, Pid, Name, Type}, _From, State) ->\n    %% Link to monitor the component\n    link(Pid),\n    \n    Component = #component{\n        name = Name,\n        type = Type\n    },\n    \n    NewComponents = maps:put(Pid, Component, State#state.components),\n    {reply, ok, State#state{components = NewComponents}};\n\nhandle_call(_Request, _From, State) ->\n    {reply, {error, unknown_request}, State}.\n\nhandle_cast({crashed, Pid}, State) ->\n    %% Handle manual crash notification\n    handle_component_exit(Pid, crashed, State);\n\nhandle_cast(_Request, State) ->\n    {noreply, State}.\n\nhandle_info({'EXIT', Pid, Reason}, State) ->\n    %% Component crashed\n    handle_component_exit(Pid, Reason, State);\n\nhandle_info(_Info, State) ->\n    {noreply, State}.\n\n%% Core logic - must be rock solid\nhandle_component_exit(Pid, Reason, State) ->\n    case maps:find(Pid, State#state.components) of\n        {ok, Component} ->\n            %% Log the crash\n            error_logger:error_msg(\n                \"Component ~p (~p) crashed: ~p~n\",\n                [Component#component.name, Component#component.type, Reason]\n            ),\n            \n            %% Update component info\n            UpdatedComponent = Component#component{\n                restarts = Component#component.restarts + 1,\n                last_crash = erlang:timestamp()\n            },\n            \n            %% Decide what to do\n            Policy = maps:get(Component#component.type, State#state.policies),\n            case Policy(UpdatedComponent) of\n                restart ->\n                    %% Restart the component\n                    restart_component(UpdatedComponent),\n                    \n                    %% Keep tracking it\n                    NewComponents = maps:put(Pid, UpdatedComponent,\n                                           State#state.components),\n                    {noreply, State#state{components = NewComponents}};\n                \n                stop ->\n                    %% Remove from tracking\n                    NewComponents = maps:remove(Pid, State#state.components),\n                    {noreply, State#state{components = NewComponents}}\n            end;\n        \n        error ->\n            %% Unknown component, ignore\n            {noreply, State}\n    end.\n\nrestart_component(#component{name = Name, type = Type}) ->\n    %% Delegate actual restart to a supervisor\n    %% The kernel doesn't do the restart itself\n    component_supervisor:restart_component(Name, Type).\n\n%% Separate supervisor for actual component management\n-module(component_supervisor).\n-behaviour(supervisor).\n\n-export([start_link/0, restart_component/2]).\n-export([init/1]).\n\nstart_link() ->\n    supervisor:start_link({local, ?MODULE}, ?MODULE, []).\n\nrestart_component(Name, Type) ->\n    %% Start a new instance of the component\n    ChildSpec = component_spec(Name, Type),\n    supervisor:start_child(?MODULE, ChildSpec).\n\ninit([]) ->\n    %% Dynamic supervisor for components\n    SupFlags = #{strategy => simple_one_for_one},\n    \n    ChildSpec = #{\n        id => component,\n        start => {component_wrapper, start_link, []},\n        restart => temporary\n    },\n    \n    {ok, {SupFlags, [ChildSpec]}}.\n\ncomponent_spec(Name, Type) ->\n    #{\n        id => Name,\n        start => {component_wrapper, start_link, [Name, Type]},\n        restart => temporary,\n        shutdown => 5000,\n        type => worker\n    }.\n\n%% Wrapper for components that registers with kernel\n-module(component_wrapper).\n\n-export([start_link/2]).\n\nstart_link(Name, Type) ->\n    Pid = spawn_link(fun() -> \n        %% Register with kernel\n        system_kernel:register_component(Name, Type),\n        \n        %% Run the actual component\n        component:run(Name)\n    end),\n    {ok, Pid}."
    }
  }
}